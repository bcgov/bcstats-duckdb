---
title: "DuckDB Evaluation"
date: today
format: html
toc: true
params:
  n_trials: 5
  nrow_check: 500
  nrow_by: !expr 10^6
  run_boolean_problem: no
  run_loop: no
editor_options: 
  chunk_output_type: inline
---

```{r setup}
pacman::p_load(tictoc, tidyverse, duckdb, zeallot)
```

# Introduction

The purpose of this project is to provide a high-level evaluation of [DuckDB](https://duckdb.org) as a solution for projects involving databases at BC Stats.

# Advantages of DuckDB

Section left blank for Jon.

# Disadvantages of DuckDB

Section left blank for Jon.

# Loading Data into DuckDB

Section left blank for Jon. Note you can use bash scripts here -- maybe useful for embedding the dbt code?

```{bash}
echo hello jon!!!
```

# Speed Tests

## Introduction

In this section, we compare the speed of certain operations between `DuckDB`, `duckplyr` and `dplyr` in R. The operations are:

-   loading .csv files as standalone R data frames or into a DuckDB database
-   querying either R data frames using `dbplyr` or `duckplyr` syntax, or querying DuckDB databases.

We will use the [`tictoc`](https://cran.r-project.org/web/packages/tictoc/index.html) package to get speed timestamps.

First, we load the packages and establish the DuckDB database. (Note that we don't load `duckplyr` directly in order to avoid overwriting `dplyr` methods. See the [duckplyr website](https://duckplyr.tidyverse.org/index.html) for more information.)

Next, we print the parameters for this run. (Adjust as needed.) `n_trials` gives the number of times to run the main loop. `nrow_check` gives the starting value for the `nrow.check` parameter of the `duckdb::duckdb_read_csv` function call for the `csv` file that causes errors when read with default values.

```{r}
params
```

We will test speeds on the following `csv` files. These are currently saved locally but I'd like to get them from the LAN.

```{r}
csvs = fs::dir_info("csvs") |> 
  select(path, size) |>
  arrange(desc(size))

csvs
```

## Issues

### Issue With Query Consistency

csvs/CLR_EXT_20231227.csv

birth_yr_mon can't use ym() in DuckDB

### Issue Reading some `csv` Files

Some `csv` files cannot be read easily into R using DuckDB. For example, in this section, `duckdb::duckdb_read_csv` throws an error using its default values on a particular `csv` file (because it incorrectly reads the `SYMBOL` column as a Boolean. The workaround is to increase the `nrow.check` parameter when `duckdb::duckdb_read_csv` is called.

```{r}
#| eval: !expr params$run_boolean_problem

problematic_csv_path = 'csvs/98-401-X2021006_English_CSV_data_BritishColumbia-utf8.csv'
db_boolean_problem = duckdb::dbConnect(duckdb::duckdb())

# this gives an error because it thinks the "SYMBOL" column is a boolean
tryCatch(
  duckdb::duckdb_read_csv(db_boolean_problem, name = "test_table", files = problematic_csv_path, header = TRUE, transaction = T),
  error = function(e) print(e)
)
```

Here, we'll define a function that increases the `nrow.check` parameter when `duckdb::duckdb_read_csv` generates an error. It stops when `duckdb::duckdb_read_csv` succeeds and returns the value of `nrow.check`.

```{r}
adjust_nrow_check = function(conn, name, files, header, transaction, nrow_check, by, quiet=T) {
  i = nrow_check
  while (T) {
    if (!quiet) message("\ni: ", i)
    tryCatch({
      duckdb::duckdb_read_csv(conn = conn, name = name, files =  files, header = header, transaction = transaction, nrow.check = i)
      return(i)
    },
    error = function(e) NULL)
    i = i + by
  }
}
```

```{r}
#| eval: !expr params$run_boolean_problem

i = adjust_nrow_check(conn = db_boolean_problem, name = "test_table", files = problematic_csv_path, header = T, transaction = T, nrow_check = params$nrow_check, by = 500)

cat("The `duckdb::duckdb_read_csv` function works when `nrow.check` ==", i)

symbol_duckdb = tbl(db_boolean_problem, "test_table") |>
  count(SYMBOL) |>
  arrange(n) |>
  collect()

symbol_duckdb
saveRDS(list(i, symbol_duckdb), "RDS/run_boolean_problem.Rds")
```

```{r}
#| eval: !expr ~params$run_boolean_problem
#| echo: false

c(i, symbol_duckdb) %<-% readRDS("RDS/run_boolean_problem.Rds")

cat("The `duckdb::duckdb_read_csv` function works when `nrow.check` ==", i)
symbol_duckdb
```

## Speed Tests

In this section, we run the main speed tests. We will compare the speeds of `dplyr`, `duckplyr` and `DuckDB`. For load times, we will compare R's `read.csv2` function with DuckDB's `read_csv_duckdb`. Each `csv` will be read and have a basic operation performed on it (equivalent to a SQL select query)---these operations are specific to each file, are entirely made up, and are saved as lists of R expressions. `exprs_dplyr` is a list containing the query expressions using `dplyr`.

```{r}
csvs$expr_dplyr = c(
  "df |>
    as_tibble() |>
    mutate(C1_COUNT_TOTAL = as.double(C1_COUNT_TOTAL)) |>
    group_by(CENSUS_YEAR, GEO_LEVEL, GEO_NAME) |>
    summarise(C1_COUNT_TOTAL = sum(C1_COUNT_TOTAL)) |>
    arrange(CENSUS_YEAR, GEO_LEVEL, GEO_NAME)",
  "df |>
    as_tibble() |>
    count(CITY, SEX) |>
    arrange(CITY, SEX)",
  "df |>
    as_tibble() |>
    pull(BIRTH_YR_MON) |>
    unique() |>
    sort()",
  "df |>
    as_tibble() |>
    count(JURISDICTION, CONVEYANCE_TYPE_DESCRIPTION) |>
    arrange(JURISDICTION, CONVEYANCE_TYPE_DESCRIPTION)",
  "df |>
    as_tibble() |>
    summarise(across(everything(), min))"
)
```

```{r}
csvs$expr_duckplyr = map_chr(csvs$expr_dplyr, ~str_replace(., "as_tibble", "duckplyr::as_duckplyr_tibble"))

csvs$expr_duck_db = map_chr(csvs$expr_dplyr, ~str_replace(., "df\\s+\\|>\\\n\\s+as\\_tibble\\(\\)\\s+", 'tbl(db, "t1") '))
```

```{r}
#| eval: !expr params$run_loop

results = csvs |>
  crossing(trial = 1:params$n_trials) |>
  mutate(
    nrow = NA_integer_,
    load_time_dplyr = NA_real_,
    load_time_nrow_check = NA_real_,
    load_time_duck_db = NA_real_,
    eval_time_dplyr = NA_real_,
    eval_time_duckplyr = NA_real_,
    eval_time_duck_db = NA_real_,
    result_dplyr = NA,
    result_duckplyr = NA,
    result_duck_db = NA
  ) |>
  arrange(trial, path)

for (i in 1:nrow(results)) {
  message("\n\niteration: ", i, " of ", nrow(results), "\ncsv: ", results$path[i], "\ntrial: ", results$trial[i], " of ", params$n_trials, "\n\n")

  expr_dplyr = parse(text = results$expr_dplyr[[i]])
  expr_duckplyr = parse(text = results$expr_duckplyr[[i]])
  expr_duck_db = parse(text = results$expr_duck_db[[i]])

  # read the csv into memory in R
  tic()
  df = read.csv2(results$path[i], sep = ",", quote = "\"", na.strings = "")
  toc(log = T)
  results[[i, 'load_time_dplyr']] = as.double(word(tail(tic.log(), 1, 1)))
    
  results[[i, 'nrow']] = nrow(df)

  # read the csv into the duck database
  db = duckdb::dbConnect(duckdb::duckdb())
  tryCatch({
    tic()
    duckdb::duckdb_read_csv(db, name = "t1", files = results$path[i], header = TRUE, transaction = T)
    toc(log = T)
    results[[i, 'load_time_duck_db']] = as.double(word(tail(tic.log(), 1, 1)))
    }, error = function(e) {
      toc()
      db_problem = duckdb::dbConnect(duckdb::duckdb())
      tic()
      n_row = adjust_nrow_check(conn = db_problem, name = "test_table", files = results$path[i], header = T, transaction = T, nrow_check = params$nrow_check, by = params$nrow_by, quiet = T)
      toc(log = T)
      results[[i, 'load_time_nrow_check']] <<- as.double(word(tail(tic.log(), 1, 1)))
      tic()
      duckdb::duckdb_read_csv(db, name = "t1", files = results$path[i], header = TRUE, transaction = T, nrow.check = n_row)
      toc(log = T)
      results[[i, 'load_time_duck_db']] <<- as.double(word(tail(tic.log(), 1, 1)))
    })
      
    # run a dplyr expression on the df
    tic()
    result_dplyr = eval(expr_dplyr)
    toc(log = T)
    results[[i, 'eval_time_dplyr']] = as.double(word(tail(tic.log(), 1, 1)))
    results[[i, 'result_dplyr']] = list(result_dplyr)

    # run a duckplyr expression on the df
    tic()
    result_duckplyr = eval(expr_duckplyr)
    toc(log = T)
    results[[i, 'eval_time_duckplyr']] = as.double(word(tail(tic.log(), 1, 1)))
    results[[i, 'result_duckplyr']] = list(result_duckplyr)

    
    # run the dbplyr expression on the DuckDB database
    tic()
    result_duck_db = eval(expr_duck_db)
    if (methods::is(result_duck_db, "tbl_lazy")) result_duck_db = collect(result_duck_db) # dbplyr expressions are 'lazy' so the total time to process must include `collect` 
    toc(log = T)
    results[[i, 'eval_time_duck_db']] = as.double(word(tail(tic.log(), 1, 1)))
    results[[i, 'result_duck_db']] = list(result_duck_db)
  }

saveRDS(results, "RDS/results.Rds")
```

## Results

In this section, we examine the results. First, we check whether the results of the queries were consistent.

```{r}
results = readRDS("RDS/results.Rds")

length_check = results |>
  arrange(path, trial) |>
  select(starts_with("result")) |>
  apply(2, unique)
  
# this should be TRUE: it checks whether the df's returned from all the trials are identical
all(map_int(length_check, length) == nrow(csvs)) 

map_int(1:nrow(csvs), function(i) {
  dfs = list()
  for (df in length_check) {
    dfs = append(dfs, df[i])
  }
  length(unique(dfs))
})

# This should be a vector of 1s of length `nrow(csvs)`. It goes line by line and, for each  each csv, returns the number of identical dataframes for each loading procedure. Any number greater than one indicates that there are differences in the loaded dataframes, which is not ideal.
```

An informal inspection of these dataframes indicates that the results are **mostly** the same. The differences are mostly due to situations in which, for example, a value is coded as `NA` in one dataframe and 0 in the other.

This next table gives the mean time for all the events.

```{r}
# means
results |>
  group_by(path) |>
  summarise(across(matches("time"), mean))
```
