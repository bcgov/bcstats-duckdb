---
title: "Duck DB, duckplyr and dplyr Speed Comparison Tests"
author: "Tim H"
date: today
format: html
toc: true
params:
  n_trials: 5
  nrow_check: 500
  nrow_by: !expr 10^6
  run_boolean_problem: no
editor_options: 
  chunk_output_type: console
---

## Introduction

The purpose of this document is to compare the speed of certain operations between `Duck DB`, `duckplyr` and `dplyr` in R. The operations are:

- loading .csv files as standalone R data frames or into a Duck DB database,
- querying either R data frames using `dbplyr` or `duckplyr` syntax, or querying Duck DB databases.

We will use the [`tictoc`](https://cran.r-project.org/web/packages/tictoc/index.html) package to get speed timestamps.

First, we load the packages and establish the duck DB database. (Note that we don't load `duckplyr` directly in order to avoid overwriting `dplyr` methods. See the [duckplyr website](https://duckplyr.tidyverse.org/index.html) for more information.)

```{r setup}
pacman::p_load(tictoc, tidyverse, duckdb, zeallot)
```

Next, we print the parameters for this run. (Adjust as needed.) `n_trials` gives the number of times to run the main loop. `nrow_check` gives the starting value for the `nrow.check` parameter of the `duckdb::duckdb_read_csv` function call for the `csv` file that causes errors when read with default values.

```{r}
params
```

We will test speeds on the following `csv` files:

```{r}
csvs = fs::dir_info("csvs") |> 
  select(path, size) |>
  arrange(desc(size))

csvs
```

## Issue With Query Consistency

csvs/CLR_EXT_20231227.csv

birth_yr_mon can't use ym() in duck db

## Issue Reading `csv` Files

Some `csv` files cannot be read easily into R using Duck DB. For example, in this section, `duckdb::duckdb_read_csv` throws an error using its default values on a particular `csv` file (because it incorrectly reads the `SYMBOL` column as a Boolean. The workaround is to increase the `nrow.check` parameter when `duckdb::duckdb_read_csv` is called.

```{r}
#| eval: !expr params$run_boolean_problem

problematic_csv_path = 'csvs/98-401-X2021006_English_CSV_data_BritishColumbia-utf8.csv'
db_boolean_problem = duckdb::dbConnect(duckdb::duckdb())

# this gives an error because it thinks the "SYMBOL" column is a boolean
tryCatch(
  duckdb::duckdb_read_csv(db_boolean_problem, name = "test_table", files = problematic_csv_path, header = TRUE, transaction = T),
  error = function(e) print(e)
)
```

Here, we'll define a function that increases the `nrow.check` parameter when `duckdb::duckdb_read_csv` generates an error. It stops when `duckdb::duckdb_read_csv` succeeds and returns the value of `nrow.check`.

```{r}
adjust_nrow_check = function(conn, name, files, header, transaction, nrow_check, by, quiet=T) {
  i = nrow_check
  while (T) {
    if (!quiet) cat("\ni: ", i)
    tryCatch({
      duckdb::duckdb_read_csv(conn = conn, name = name, files =  files, header = header, transaction = transaction, nrow.check = i)
      return(i)
    },
    error = function(e) NULL)
    i = i + by
  }
}
```

```{r}
#| eval: !expr params$run_boolean_problem

i = adjust_nrow_check(conn = db_boolean_problem, name = "test_table", files = problematic_csv_path, header = T, transaction = T, nrow_check = params$nrow_check, by = 500)

cat("The `duckdb::duckdb_read_csv` function works when `nrow.check` ==", i)

symbol_duckdb = tbl(db_boolean_problem, "test_table") |>
  count(SYMBOL) |>
  arrange(n) |>
  collect()

symbol_duckdb
saveRDS(list(i, symbol_duckdb), "RDS/run_boolean_problem.Rds")
```

```{r}
#| eval: !expr ~params$run_boolean_problem
#| echo: false

c(i, symbol_duckdb) %<-% readRDS("RDS/run_boolean_problem.Rds")

cat("The `duckdb::duckdb_read_csv` function works when `nrow.check` ==", i)
symbol_duckdb
```

## Speed Tests

In this section, we run the main speed tests. We will compare the speeds of `dplyr`, `duckplyr` and `Duck DB`. For load times, we will compare R's `read.csv2` function with Duck DB's `read_csv_duckdb`. Each `csv` will be read and have a basic operation performed on it (equivalent to a SQL select query)---these operations are specific to each file, are entirely made up, and are saved as lists of R expressions. `exprs_dplyr` is a list containing the query expressions using `dplyr`.

```{r}
csvs$expr_dplyr = list(
  "df |>
    mutate(C1_COUNT_TOTAL = as.double(C1_COUNT_TOTAL)) |>
    group_by(CENSUS_YEAR, GEO_LEVEL, GEO_NAME) |>
    summarise(sum(C1_COUNT_TOTAL))",
  "df |>
    count(CITY, SEX)",
  "df |>
    pull(BIRTH_YR_MON) |>
    unique() |>
    sort()",
  "df |>
    count(JURISDICTION, CONVEYANCE_TYPE_DESCRIPTION)",
  "df |>
    summarise(across(everything(), min))"
)
```

```{r}
csvs$expr_duckplyr = map(csvs$expr_dplyr, ~str_replace(., "df |>", "df |>\n    duckplyr::as_duckplyr_tibble()"))

csvs$expr_duck_db = map(csvs$expr_dplyr, ~str_replace(., "df |>", 'tbl(db, "t1")'))
```


```{r}
results = csvs |>
  crossing(trial = 1:params$n_trials) |>
  mutate(
    nrow = NA_integer_,
    load_time_dplyr = NA_real_,
    load_time_nrow_check = NA_real_,
    load_time_duck_db = NA_real_,
    eval_time_dplyr = NA_real_,
    eval_time_duckplyr = NA_real_,
    eval_time_duck_db = NA_real_,
    result_dplyr = NA,
    result_duckplyr = NA,
    result_duck_db = NA
  ) |>
  arrange(trial, path)

for (i in 1:nrow(results)) {
  cat("\n\niteration:", i, "\ncsv:", results$path[i], "\ntrial:", results$trial[i], "\n\n")

  expr_dplyr = parse(text = results$expr_dplyr[[i]])
  expr_duckplyr = parse(text = results$expr_duckplyr[[i]])
  expr_duck_db = parse(text = results$expr_duck_db[[i]])

  # read the csv into memory in R
  tic()
  df = read.csv2(results$path[i], sep = ",", quote = "\"", na.strings = "")
  toc(log = T)
  results[[i, 'load_time_dplyr']] = as.double(word(tail(tic.log(), 1, 1)))
    
  results[[i, 'nrow']] = nrow(df)

  # read the csv into the duck database
  db = duckdb::dbConnect(duckdb::duckdb())
  tryCatch({
    tic()
    duckdb::duckdb_read_csv(db, name = "t1", files = results$path[i], header = TRUE, transaction = T)
    toc(log = T)
    results[[i, 'load_time_duck_db']] = as.double(word(tail(tic.log(), 1, 1)))
    }, error = function(e) {
      toc()
      db_problem = duckdb::dbConnect(duckdb::duckdb())
      tic()
      n_row = adjust_nrow_check(conn = db_problem, name = "test_table", files = results$path[i], header = T, transaction = T, nrow_check = params$nrow_check, by = params$nrow_by, quiet = T)
      toc(log = T)
      results[[i, 'load_time_nrow_check']] <<- as.double(word(tail(tic.log(), 1, 1)))
      tic()
      duckdb::duckdb_read_csv(db, name = "t1", files = results$path[i], header = TRUE, transaction = T, nrow.check = n_row)
      toc(log = T)
      results[[i, 'load_time_duck_db']] <<- as.double(word(tail(tic.log(), 1, 1)))
    })
      
    # run a dplyr expression on the df
    tic()
    result_dplyr = eval(expr_dplyr)
    toc(log = T)
    results[[i, 'eval_time_dplyr']] = as.double(word(tail(tic.log(), 1, 1)))
    results[[i, 'result_dplyr']] = list(result_dplyr)

    # run a duckplyr expression on the df
    tic()
    result_duckplyr = eval(expr_duckplyr)
    toc(log = T)
    results[[i, 'eval_time_duckplyr']] = as.double(word(tail(tic.log(), 1, 1)))
    results[[i, 'result_duckplyr']] = list(result_duckplyr)

    
    # run the dbplyr expression on the duck db database
    tic()
    result_duck_db = eval(expr_duck_db)
    if (methods::is(result_duck_db, "tbl_lazy")) result_duck_db = collect(result_duck_db) # dbplyr expressions are 'lazy' so the total time to process must include `collect` 
    toc(log = T)
    results[[i, 'eval_time_duck_db']] = as.double(word(tail(tic.log(), 1, 1)))
    results[[i, 'result_duck_db']] = list(result_duck_db)
    
  View(results)

  }

saveRDS(results, "RDS/results.Rds")
```




```{r}


# total time (almost)
# sum(results[, 6:10]) / 60
# 
# 
# # means
# results |>
#   group_by(csv) |>
#   summarise(across(matches("time"), mean))
# 
# # means graphed
# results |>
#   group_by(csv) |>
#   summarise(across(matches("time"), mean)) |>
#   pivot_longer(cols = -1) |>
#   mutate(is_load = str_detect(name, "load")) |>
#   ggplot(aes(x=name, y=value, fill=is_load)) +
#   geom_col() +
#   facet_wrap(vars(csv), scales='free') +
#   ggthemes::theme_clean() +
#   theme(legend.position = 'none')
# 
# # snazzy histogram - maybe gives a sense of the distribution of times?
# results |>
#   select(n, csv, matches("time")) |>
#   pivot_longer(cols = 3:7) |>
#   ggplot(aes(x=value, fill=name)) +
#   geom_histogram() +
#   facet_wrap(vars(name, csv), scales='free') +
#   ggthemes::theme_clean() +
#   theme(legend.position = 'none')

```

